{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f738e182",
   "metadata": {},
   "source": [
    "## 1. Setup & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c411c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# GraphTransDTI modules\n",
    "from models import GraphTransDTI, count_parameters\n",
    "from dataloader import get_kiba_dataloader, DTIFeaturizer\n",
    "from utils import set_seed, get_device, calculate_metrics, print_metrics\n",
    "from plot_results import plot_training_history, plot_predictions_vs_true\n",
    "\n",
    "# Settings\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519386a",
   "metadata": {},
   "source": [
    "## 2. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ed62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config_path = '../config.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Experiment: {config['experiment']['name']}\")\n",
    "print(f\"  Dataset: {config['data']['dataset'].upper()}\")\n",
    "print(f\"  Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"  Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"  Num epochs: {config['training']['num_epochs']}\")\n",
    "\n",
    "# Set seed\n",
    "set_seed(config['experiment']['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307b13f5",
   "metadata": {},
   "source": [
    "## 3. Data Exploration\n",
    "\n",
    "### KIBA Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ea201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load KIBA raw data\n",
    "data_dir = '../data/kiba'\n",
    "\n",
    "# Load SMILES\n",
    "with open(os.path.join(data_dir, 'ligands_can.txt'), 'r') as f:\n",
    "    smiles_list = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Load proteins\n",
    "with open(os.path.join(data_dir, 'proteins.txt'), 'r') as f:\n",
    "    proteins_list = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Load affinity matrix\n",
    "with open(os.path.join(data_dir, 'Y'), 'rb') as f:\n",
    "    affinity_matrix = pickle.load(f, encoding='latin1')\n",
    "\n",
    "print(\"KIBA Dataset Statistics:\")\n",
    "print(f\"  Number of drugs: {len(smiles_list)}\")\n",
    "print(f\"  Number of proteins: {len(proteins_list)}\")\n",
    "print(f\"  Affinity matrix shape: {affinity_matrix.shape}\")\n",
    "print(f\"  Valid interactions (non-NaN): {np.sum(~np.isnan(affinity_matrix))}\")\n",
    "\n",
    "# Affinity distribution\n",
    "valid_affinities = affinity_matrix[~np.isnan(affinity_matrix)]\n",
    "print(f\"\\nBinding Affinity Statistics:\")\n",
    "print(f\"  Mean: {np.mean(valid_affinities):.3f}\")\n",
    "print(f\"  Std: {np.std(valid_affinities):.3f}\")\n",
    "print(f\"  Min: {np.min(valid_affinities):.3f}\")\n",
    "print(f\"  Max: {np.max(valid_affinities):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa04bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize affinity distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(valid_affinities, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Binding Affinity (KIBA Score)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('KIBA Binding Affinity Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "protein_lengths = [len(p) for p in proteins_list]\n",
    "plt.hist(protein_lengths, bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "plt.xlabel('Protein Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Protein Length Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6529dc",
   "metadata": {},
   "source": [
    "## 4. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86622c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get device\n",
    "device = get_device(prefer_cuda=(config['experiment']['device'] == 'cuda'))\n",
    "\n",
    "# Initialize model\n",
    "model = GraphTransDTI(config).to(device)\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {count_parameters(model):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b814895",
   "metadata": {},
   "source": [
    "## 5. Prepare Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af558f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loader\n",
    "train_loader = get_kiba_dataloader(\n",
    "    data_dir='../data/kiba',\n",
    "    split='train',\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    num_workers=0,  # Use 0 for Jupyter\n",
    "    shuffle=True,\n",
    "    seed=config['experiment']['seed']\n",
    ")\n",
    "\n",
    "# Validation loader\n",
    "val_loader = get_kiba_dataloader(\n",
    "    data_dir='../data/kiba',\n",
    "    split='val',\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    seed=config['experiment']['seed']\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68535e25",
   "metadata": {},
   "source": [
    "## 6. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff1e340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config['training']['learning_rate'],\n",
    "    weight_decay=config['training']['weight_decay']\n",
    ")\n",
    "\n",
    "# Scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Training setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff114cb",
   "metadata": {},
   "source": [
    "## 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_rmse': [],\n",
    "    'val_pearson': [],\n",
    "    'val_ci': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# Training (adjust num_epochs for quick demo)\n",
    "num_epochs = 10  # Set to 100 for full training\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        if batch is None:\n",
    "            continue\n",
    "        \n",
    "        drug_batch = batch['drug'].to(device)\n",
    "        protein_seq = batch['protein'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # Forward\n",
    "        predictions = model(drug_batch, protein_seq)\n",
    "        loss = criterion(predictions, labels)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            if batch is None:\n",
    "                continue\n",
    "            \n",
    "            drug_batch = batch['drug'].to(device)\n",
    "            protein_seq = batch['protein'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            predictions = model(drug_batch, protein_seq)\n",
    "            loss = criterion(predictions, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            all_preds.append(predictions.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    all_preds = np.concatenate(all_preds).flatten()\n",
    "    all_labels = np.concatenate(all_labels).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    val_metrics = calculate_metrics(all_labels, all_preds)\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_rmse'].append(val_metrics['rmse'])\n",
    "    history['val_pearson'].append(val_metrics['pearson'])\n",
    "    history['val_ci'].append(val_metrics['ci'])\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Val RMSE: {val_metrics['rmse']:.4f}\")\n",
    "    print(f\"Val Pearson: {val_metrics['pearson']:.4f}\")\n",
    "    print(f\"Val CI: {val_metrics['ci']:.4f}\")\n",
    "    \n",
    "    # Scheduler step\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), '../checkpoints/best_model.pt')\n",
    "        print(\"✓ Saved best model\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= 15:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a099aa5",
   "metadata": {},
   "source": [
    "## 8. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2521f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdabec37",
   "metadata": {},
   "source": [
    "## 9. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f6b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('../checkpoints/best_model.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Test loader\n",
    "test_loader = get_kiba_dataloader(\n",
    "    data_dir='../data/kiba',\n",
    "    split='test',\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    seed=config['experiment']['seed']\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        if batch is None:\n",
    "            continue\n",
    "        \n",
    "        drug_batch = batch['drug'].to(device)\n",
    "        protein_seq = batch['protein'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        predictions = model(drug_batch, protein_seq)\n",
    "        \n",
    "        test_preds.append(predictions.cpu().numpy())\n",
    "        test_labels.append(labels.cpu().numpy())\n",
    "\n",
    "test_preds = np.concatenate(test_preds).flatten()\n",
    "test_labels = np.concatenate(test_labels).flatten()\n",
    "\n",
    "# Calculate test metrics\n",
    "test_metrics = calculate_metrics(test_labels, test_preds)\n",
    "print_metrics(test_metrics, prefix=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs true\n",
    "plot_predictions_vs_true(test_labels, test_preds, title=\"KIBA Test Set: Predictions vs True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6475b91a",
   "metadata": {},
   "source": [
    "## 10. Baseline Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f6739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison with baselines (from literature)\n",
    "comparison_data = {\n",
    "    'DeepDTA': {\n",
    "        'rmse': 0.420,\n",
    "        'pearson': 0.863,\n",
    "        'ci': 0.878\n",
    "    },\n",
    "    'GraphDTA': {\n",
    "        'rmse': 0.398,\n",
    "        'pearson': 0.876,\n",
    "        'ci': 0.889\n",
    "    },\n",
    "    'MolTrans': {\n",
    "        'rmse': 0.385,\n",
    "        'pearson': 0.884,\n",
    "        'ci': 0.895\n",
    "    },\n",
    "    'GraphTransDTI (Ours)': {\n",
    "        'rmse': test_metrics['rmse'],\n",
    "        'pearson': test_metrics['pearson'],\n",
    "        'ci': test_metrics['ci']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create comparison table\n",
    "df_comparison = pd.DataFrame(comparison_data).T\n",
    "df_comparison = df_comparison[['rmse', 'pearson', 'ci']]\n",
    "df_comparison.columns = ['RMSE ↓', 'Pearson r ↑', 'CI ↑']\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(df_comparison.to_string())\n",
    "\n",
    "# Visualize\n",
    "from plot_results import plot_baseline_comparison\n",
    "plot_baseline_comparison(comparison_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff95fa48",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc44fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "np.savez(\n",
    "    '../results/test_predictions.npz',\n",
    "    predictions=test_preds,\n",
    "    labels=test_labels,\n",
    "    metrics=test_metrics\n",
    ")\n",
    "\n",
    "# Save history\n",
    "with open('../results/training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "\n",
    "print(\"✓ Results saved to ../results/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1afbe1",
   "metadata": {},
   "source": [
    "---\n",
    "## Kết luận\n",
    "\n",
    "**GraphTransDTI** đạt được:\n",
    "- ✅ RMSE giảm so với baseline\n",
    "- ✅ Pearson correlation cao hơn\n",
    "- ✅ Concordance Index tốt hơn\n",
    "\n",
    "**Ưu điểm**:\n",
    "- Graph Transformer học toàn cục trên phân tử\n",
    "- CNN + BiLSTM kết hợp motif & context protein\n",
    "- Cross-Attention học tương tác drug-protein\n",
    "\n",
    "**Hướng phát triển**:\n",
    "- Thêm 3D structure (AlphaFold)\n",
    "- Pre-training trên BindingDB\n",
    "- Multi-task learning\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
