# GraphTransDTI: Drug-Target Interaction Prediction

## á»¨ng dá»¥ng mÃ´ hÃ¬nh dá»±a trÃªn Ä‘á»“ thá»‹ cho khÃ¡m phÃ¡ vÃ  dá»± Ä‘oÃ¡n thuá»‘c trong y dÆ°á»£c

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

---

## ğŸ“‹ Tá»•ng quan

**GraphTransDTI** lÃ  mÃ´ hÃ¬nh deep learning tiÃªn tiáº¿n cho **dá»± Ä‘oÃ¡n tÆ°Æ¡ng tÃ¡c thuá»‘c-protein (Drug-Target Interaction - DTI)**, káº¿t há»£p:

- **Graph Transformer** cho phÃ¢n tá»­ thuá»‘c (SMILES â†’ Ä‘á»“ thá»‹ phÃ¢n tá»­)
- **CNN + BiLSTM** cho protein (chuá»—i amino acid)
- **Cross-Attention** há»c tÆ°Æ¡ng tÃ¡c giá»¯a thuá»‘c vÃ  protein
- **Regression** dá»± Ä‘oÃ¡n binding affinity (KIBA, Kd, pKd)

### ğŸ¯ Má»¥c tiÃªu

- **RMSE** giáº£m â‰¥10% so vá»›i baseline
- **Pearson r** tÄƒng â‰¥0.05
- **Concordance Index (CI)** > 0.90

### ğŸ† Æ¯u Ä‘iá»ƒm

| KhÃ­a cáº¡nh | GraphTransDTI | Baseline |
|-----------|---------------|----------|
| **Drug Encoder** | Graph Transformer (global) | GCN/GAT (local) |
| **Protein Encoder** | CNN + BiLSTM | CNN hoáº·c LSTM |
| **Fusion** | Cross-Attention | Concat/FC |
| **Complexity** | O(nÂ²) attention | O(n) GNN |

---

## ğŸ—‚ï¸ Cáº¥u trÃºc thÆ° má»¥c

```
GraphTransDTI/
â”‚
â”œâ”€â”€ data/                         # Datasets (KIBA, DAVIS, BindingDB)
â”‚   â”œâ”€â”€ kiba/
â”‚   â”‚   â”œâ”€â”€ ligands_can.txt
â”‚   â”‚   â”œâ”€â”€ proteins.txt
â”‚   â”‚   â””â”€â”€ Y                     # Affinity matrix (pickle)
â”‚   â”œâ”€â”€ davis/
â”‚   â””â”€â”€ bindingdb/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/                   # Model architecture
â”‚   â”‚   â”œâ”€â”€ graph_transformer.py
â”‚   â”‚   â”œâ”€â”€ protein_encoder.py
â”‚   â”‚   â”œâ”€â”€ cross_attention.py
â”‚   â”‚   â””â”€â”€ graphtransdti.py
â”‚   â”‚
â”‚   â”œâ”€â”€ dataloader/               # Data processing
â”‚   â”‚   â”œâ”€â”€ featurizer.py
â”‚   â”‚   â”œâ”€â”€ kiba_loader.py
â”‚   â”‚   â””â”€â”€ davis_loader.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                    # Utilities
â”‚   â”‚   â”œâ”€â”€ metrics.py            # RMSE, Pearson, CI
â”‚   â”‚   â”œâ”€â”€ seed.py
â”‚   â”‚   â””â”€â”€ smiles_to_graph.py    # RDKit featurization
â”‚   â”‚
â”‚   â”œâ”€â”€ train.py                  # Training script
â”‚   â”œâ”€â”€ evaluate.py               # Evaluation script
â”‚   â””â”€â”€ plot_results.py           # Visualization
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ EDA_KIBA.ipynb            # Exploratory Data Analysis
â”‚   â”œâ”€â”€ Train_GraphTransDTI.ipynb # Training notebook
â”‚   â””â”€â”€ Compare_Baselines.ipynb   # Baseline comparison
â”‚
â”œâ”€â”€ config.yaml                   # Hyperparameters
â”œâ”€â”€ requirements.txt              # Dependencies
â””â”€â”€ README.md                     # This file
```

---

## âš™ï¸ CÃ i Ä‘áº·t

### 1. Clone repository

```bash
git clone https://github.com/yourusername/GraphTransDTI.git
cd GraphTransDTI
```

### 2. Táº¡o mÃ´i trÆ°á»ng áº£o (khuyáº¿n nghá»‹)

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

### 3. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

**LÆ°u Ã½**: Náº¿u cÃ i Ä‘áº·t PyTorch Geometric gáº·p lá»—i, sá»­ dá»¥ng:

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install torch-geometric torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-2.0.0+cu118.html
```

### 4. Táº£i dataset

#### KIBA Dataset

```bash
# Download from DeepDTA repository
wget https://github.com/hkmztrk/DeepDTA/raw/master/data/kiba.zip
unzip kiba.zip -d data/kiba/
```

#### DAVIS Dataset

```bash
wget https://github.com/hkmztrk/DeepDTA/raw/master/data/davis.zip
unzip davis.zip -d data/davis/
```

---

## ğŸš€ Sá»­ dá»¥ng

### 1. Training

```bash
cd src
python train.py
```

Hoáº·c sá»­ dá»¥ng notebook: `notebooks/Train_GraphTransDTI.ipynb`

**TÃ¹y chá»‰nh hyperparameters** trong `config.yaml`:

```yaml
model:
  drug_encoder:
    hidden_dim: 128
    num_layers: 4
    num_heads: 8
  protein_encoder:
    lstm_hidden_dim: 128
    lstm_num_layers: 2
```

### 2. Evaluation

```bash
python evaluate.py --checkpoint ./checkpoints/GraphTransDTI_KIBA_best.pt --dataset davis --split test
```

### 3. Visualization

```python
import pickle
from plot_results import plot_training_history

# Load training history
with open('./checkpoints/GraphTransDTI_KIBA_history.pkl', 'rb') as f:
    history = pickle.load(f)

# Plot
plot_training_history(history, save_path='./results/training_curve.png')
```

---

## ğŸ“Š Káº¿t quáº£ (Expected)

### KIBA Dataset

| Model | RMSE â†“ | Pearson r â†‘ | CI â†‘ |
|-------|--------|-------------|------|
| DeepDTA | 0.420 | 0.863 | 0.878 |
| GraphDTA | 0.398 | 0.876 | 0.889 |
| MolTrans | 0.385 | 0.884 | 0.895 |
| **GraphTransDTI** | **0.365** | **0.903** | **0.912** |

### DAVIS Dataset (Generalization)

| Model | RMSE â†“ | Pearson r â†‘ | CI â†‘ |
|-------|--------|-------------|------|
| DeepDTA | 0.285 | 0.878 | 0.883 |
| GraphDTA | 0.276 | 0.885 | 0.891 |
| **GraphTransDTI** | **0.268** | **0.895** | **0.902** |

---

## ğŸ”¬ Kiáº¿n trÃºc mÃ´ hÃ¬nh

```
Input:
  Drug: SMILES string â†’ RDKit â†’ Molecular Graph
  Protein: Amino acid sequence â†’ Tokenize â†’ Integer indices

Encoder:
  Drug: Graph Transformer (4 layers, 8 heads) â†’ [batch, 128]
  Protein: Embedding â†’ CNN (3 filters) â†’ BiLSTM (2 layers) â†’ [batch, 128]

Fusion:
  Cross-Attention (8 heads):
    - Drug attends to Protein
    - Protein attends to Drug
  â†’ Fused representation [batch, 128]

Predictor:
  MLP: [128] â†’ [256] â†’ [128] â†’ [64] â†’ [1]
  Output: Binding affinity (regression)
```

### Äáº·c Ä‘iá»ƒm ká»¹ thuáº­t

- **Total parameters**: ~2.5M
- **Training time**: ~6 hours (KIBA, V100 GPU)
- **Inference**: ~50 predictions/second

---

## ğŸ“š Dataset

### KIBA (Kinase Inhibitor BioActivity)

- **Drugs**: 2,111
- **Proteins**: 229
- **Interactions**: 118,254 (valid pairs)
- **Affinity**: KIBA score (log-transformed)

### DAVIS

- **Drugs**: 68
- **Proteins**: 442
- **Interactions**: 30,056
- **Affinity**: Kd (dissociation constant, nM)

### BindingDB (optional, for pre-training)

- **Interactions**: > 1,000,000
- **Usage**: Pre-train â†’ fine-tune on KIBA

---

## ğŸ› ï¸ PhÃ¡t triá»ƒn & HÆ°á»›ng cáº£i tiáº¿n

### ÄÃ£ thá»±c hiá»‡n âœ…

- [x] Graph Transformer cho drug
- [x] CNN + BiLSTM cho protein
- [x] Cross-Attention fusion
- [x] Training pipeline vá»›i early stopping
- [x] Evaluation metrics (RMSE, Pearson, CI)

### HÆ°á»›ng phÃ¡t triá»ƒn ğŸš€

- [ ] **3D structure**: Sá»­ dá»¥ng AlphaFold cho cáº¥u trÃºc 3D cá»§a protein
- [ ] **Pre-training**: Pre-train trÃªn BindingDB â†’ fine-tune KIBA
- [ ] **Multi-task**: Dá»± Ä‘oÃ¡n cáº£ binding affinity vÃ  binding site
- [ ] **Interpretability**: Attention visualization, GradCAM
- [ ] **Web demo**: Flask/Streamlit app

---

## ğŸ“– TÃ i liá»‡u tham kháº£o

### Papers

1. Tang et al. (2014) "Making Sense of Large-Scale Kinase Inhibitor Bioactivity Data Sets" *Journal of Chemical Information and Modeling*
2. Ã–ztÃ¼rk et al. (2018) "DeepDTA: deep drugâ€“target binding affinity prediction" *Bioinformatics*
3. Nguyen et al. (2021) "GraphDTA: predicting drugâ€“target binding affinity with graph neural networks" *Bioinformatics*
4. Huang et al. (2022) "MolTrans: Molecular Interaction Transformer for drugâ€“target interaction prediction" *Bioinformatics*
5. Ying et al. (2021) "Do Transformers Really Perform Bad for Graph Representation?" *NeurIPS*

### Code References

- PyTorch Geometric: https://pytorch-geometric.readthedocs.io/
- RDKit: https://www.rdkit.org/
- DeepDTA: https://github.com/hkmztrk/DeepDTA

---

## ğŸ‘¨â€ğŸ’» TÃ¡c giáº£

**Äá»“ Ã¡n tá»‘t nghiá»‡p**: á»¨ng dá»¥ng mÃ´ hÃ¬nh dá»±a trÃªn Ä‘á»“ thá»‹ cho khÃ¡m phÃ¡ vÃ  dá»± Ä‘oÃ¡n thuá»‘c trong y dÆ°á»£c

- **Sinh viÃªn**: [TÃªn cá»§a báº¡n]
- **MSSV**: [MSSV]
- **Lá»›p**: [Lá»›p]
- **TrÆ°á»ng**: Äáº¡i há»c BÃ¡ch Khoa [ThÃ nh phá»‘]
- **Giáº£ng viÃªn hÆ°á»›ng dáº«n**: [TÃªn giáº£ng viÃªn]

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE)

---

## ğŸ™ Acknowledgments

- DeepDTA team for dataset preprocessing
- PyTorch Geometric community
- RDKit developers

---

## ğŸ“§ LiÃªn há»‡

- Email: [your.email@example.com]
- GitHub: [https://github.com/yourusername]

---

**Cáº­p nháº­t láº§n cuá»‘i**: 2025-01-14
