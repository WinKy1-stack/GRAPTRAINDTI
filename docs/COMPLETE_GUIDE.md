# H∆Ø·ªöNG D·∫™N HO√ÄN CH·ªàNH - GraphTransDTI
## ·ª®ng d·ª•ng m√¥ h√¨nh d·ª±a tr√™n ƒë·ªì th·ªã cho kh√°m ph√° v√† d·ª± ƒëo√°n thu·ªëc trong y d∆∞·ª£c

---

## üìö M·ª§C L·ª§C

1. [Gi·ªõi thi·ªáu](#1-gi·ªõi-thi·ªáu)
2. [C√†i ƒë·∫∑t](#2-c√†i-ƒë·∫∑t)
3. [Chu·∫©n b·ªã d·ªØ li·ªáu](#3-chu·∫©n-b·ªã-d·ªØ-li·ªáu)
4. [Ch·∫°y training](#4-ch·∫°y-training)
5. [Evaluation](#5-evaluation)
6. [K·∫øt qu·∫£ mong ƒë·ª£i](#6-k·∫øt-qu·∫£-mong-ƒë·ª£i)
7. [Troubleshooting](#7-troubleshooting)
8. [B√°o c√°o ƒë·ªì √°n](#8-b√°o-c√°o-ƒë·ªì-√°n)

---

## 1. Gi·ªõi thi·ªáu

### M·ª•c ti√™u ƒë·ªì √°n
X√¢y d·ª±ng m√¥ h√¨nh **GraphTransDTI** ƒë·ªÉ d·ª± ƒëo√°n **t∆∞∆°ng t√°c thu·ªëc-protein (DTI)** v·ªõi ƒë·ªô ch√≠nh x√°c cao h∆°n c√°c baseline hi·ªán c√≥.

### ƒê√≥ng g√≥p ch√≠nh
- ‚úÖ **Graph Transformer** cho drug (thay v√¨ GCN/GAT)
- ‚úÖ **CNN + BiLSTM** cho protein (thay v√¨ CNN/LSTM ƒë∆°n)
- ‚úÖ **Cross-Attention** fusion (thay v√¨ concat)
- ‚úÖ ƒê√°nh gi√° tr√™n **KIBA** (train) & **DAVIS** (generalization)

### K·∫øt qu·∫£ mong ƒë·ª£i
- **RMSE**: Gi·∫£m ‚â•10% so v·ªõi GraphDTA
- **Pearson r**: TƒÉng ‚â•0.05
- **CI**: > 0.90

---

## 2. C√†i ƒë·∫∑t

### B∆∞·ªõc 1: Clone repository
```bash
cd C:\Workspace\DACNTT_Nhu
# (ho·∫∑c n∆°i b·∫°n ƒë√£ clone)
```

### B∆∞·ªõc 2: T·∫°o m√¥i tr∆∞·ªùng ·∫£o
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

### B∆∞·ªõc 3: C√†i ƒë·∫∑t dependencies
```powershell
cd GraphTransDTI
pip install -r src/requirements.txt
```

**N·∫øu PyTorch Geometric l·ªói**:
```powershell
# Install PyTorch v·ªõi CUDA (n·∫øu c√≥ GPU)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install PyG
pip install torch-geometric
pip install torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-2.0.0+cu118.html
```

### B∆∞·ªõc 4: Ki·ªÉm tra c√†i ƒë·∫∑t
```powershell
python check_installation.py
```

K·∫øt qu·∫£ mong ƒë·ª£i:
```
‚úì PyTorch                  | Version: 2.0.0
‚úì PyTorch Geometric        | Version: 2.3.0
‚úì RDKit                    | Version: 2022.9.1
...
‚úì All dependencies are installed correctly!
```

---

## 3. Chu·∫©n b·ªã d·ªØ li·ªáu

### KIBA Dataset (b·∫Øt bu·ªôc)

#### Option 1: Download t·ª´ GitHub
```powershell
cd data\kiba

# Download ligands
Invoke-WebRequest -Uri "https://github.com/hkmztrk/DeepDTA/raw/master/data/kiba/ligands_can.txt" -OutFile "ligands_can.txt"

# Download proteins
Invoke-WebRequest -Uri "https://github.com/hkmztrk/DeepDTA/raw/master/data/kiba/proteins.txt" -OutFile "proteins.txt"

# Download affinity matrix
Invoke-WebRequest -Uri "https://github.com/hkmztrk/DeepDTA/raw/master/data/kiba/Y" -OutFile "Y"

cd ..\..
```

#### Option 2: Download th·ªß c√¥ng
1. V√†o https://github.com/hkmztrk/DeepDTA/tree/master/data/kiba
2. Download 3 files: `ligands_can.txt`, `proteins.txt`, `Y`
3. ƒê·∫∑t v√†o `GraphTransDTI/data/kiba/`

### DAVIS Dataset (ƒë·ªÉ test generalization)
```powershell
cd data\davis

Invoke-WebRequest -Uri "https://github.com/hkmztrk/DeepDTA/raw/master/data/davis/ligands_can.txt" -OutFile "ligands_can.txt"
Invoke-WebRequest -Uri "https://github.com/hkmztrk/DeepDTA/raw/master/data/davis/proteins.txt" -OutFile "proteins.txt"
Invoke-WebRequest -Uri "https://github.com/hkmztrk/DeepDTA/raw/master/data/davis/Y" -OutFile "Y"

cd ..\..
```

### Ki·ªÉm tra d·ªØ li·ªáu
```powershell
cd src
python -c "from dataloader import get_kiba_dataloader; get_kiba_dataloader('../data/kiba', 'train', batch_size=4, num_workers=0)"
```

---

## 4. Ch·∫°y training

### Option 1: Command line (khuy·∫øn ngh·ªã)
```powershell
cd src
python train.py
```

**Output mong ƒë·ª£i**:
```
==========================================
GraphTransDTI Training
==========================================
Experiment: GraphTransDTI_KIBA
Dataset: KIBA
Device: cuda
==========================================

[INFO] Model parameters: 2,234,567
[INFO] KIBA TRAIN dataset loaded: 94603 pairs
[INFO] KIBA VAL dataset loaded: 11825 pairs

========================================
Epoch 1/100
========================================
Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1478/1478 [03:21<00:00]
Train Loss: 0.4521
Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 185/185 [00:32<00:00]
Val Loss: 0.3876

==========================================
Validation Metrics:
==========================================
RMSE:            0.6224
Pearson r:       0.8543 (p=0.0e+00)
Concordance Index: 0.8821
==========================================

‚úì Saved best model (val_loss: 0.3876)
...
```

### Option 2: Jupyter Notebook
1. M·ªü `notebooks/Train_GraphTransDTI.ipynb`
2. Ch·∫°y t·ª´ng cell theo th·ª© t·ª±

### T√πy ch·ªânh hyperparameters
S·ª≠a file `config.yaml`:
```yaml
training:
  batch_size: 64        # Gi·∫£m n·∫øu h·∫øt RAM
  learning_rate: 0.0001
  num_epochs: 100       # Gi·∫£m xu·ªëng 10 ƒë·ªÉ test nhanh
```

---

## 5. Evaluation

### Test tr√™n KIBA (test set)
```powershell
python evaluate.py --checkpoint ..\checkpoints\GraphTransDTI_KIBA_best.pt --dataset kiba --split test
```

### Test tr√™n DAVIS (generalization)
```powershell
python evaluate.py --checkpoint ..\checkpoints\GraphTransDTI_KIBA_best.pt --dataset davis --split test
```

### Visualize results
```powershell
python plot_results.py
```

---

## 6. K·∫øt qu·∫£ mong ƒë·ª£i

### KIBA (Training dataset)

| Metric | Target | Th·ª±c t·∫ø (sau training) |
|--------|--------|------------------------|
| RMSE | < 0.370 | _[Ghi k·∫øt qu·∫£ c·ªßa b·∫°n]_ |
| Pearson r | > 0.88 | _[Ghi k·∫øt qu·∫£ c·ªßa b·∫°n]_ |
| CI | > 0.90 | _[Ghi k·∫øt qu·∫£ c·ªßa b·∫°n]_ |

### DAVIS (Generalization)

| Metric | Target | Th·ª±c t·∫ø |
|--------|--------|---------|
| RMSE | < 0.270 | _[Ghi]_ |
| Pearson r | > 0.89 | _[Ghi]_ |
| CI | > 0.89 | _[Ghi]_ |

### So s√°nh v·ªõi baseline

| Model | RMSE (KIBA) | Pearson r | CI |
|-------|-------------|-----------|-----|
| DeepDTA | 0.420 | 0.863 | 0.878 |
| GraphDTA | 0.398 | 0.876 | 0.889 |
| MolTrans | 0.385 | 0.884 | 0.895 |
| **GraphTransDTI** | **_[Ghi]_** | **_[Ghi]_** | **_[Ghi]_** |

---

## 7. Troubleshooting

### L·ªói: "CUDA out of memory"
**Gi·∫£i ph√°p**:
```yaml
# Gi·∫£m batch_size trong config.yaml
training:
  batch_size: 32  # ho·∫∑c 16
```

### L·ªói: "RDKit invalid SMILES"
**Gi·∫£i ph√°p**: M·ªôt s·ªë SMILES kh√¥ng h·ª£p l·ªá s·∫Ω t·ª± ƒë·ªông b·ªè qua. N·∫øu qu√° nhi·ªÅu:
```python
# Check trong src/dataloader/featurizer.py
# Line ~90: return None if invalid
```

### L·ªói: "pickle.UnpicklingError"
**Gi·∫£i ph√°p**:
```python
# Trong kiba_loader.py, th√™m encoding
with open(affinity_file, 'rb') as f:
    affinity_matrix = pickle.load(f, encoding='latin1')
```

### Training qu√° l√¢u
**Gi·∫£i ph√°p**:
1. Gi·∫£m `num_epochs` xu·ªëng 10 ƒë·ªÉ test
2. S·ª≠ d·ª•ng GPU (n·∫øu c√≥)
3. TƒÉng `batch_size` (n·∫øu ƒë·ªß RAM)

### Mu·ªën ch·∫°y nhanh ƒë·ªÉ demo
```yaml
# config.yaml
training:
  batch_size: 128      # TƒÉng
  num_epochs: 10       # Gi·∫£m
data:
  train_ratio: 0.1     # Ch·ªâ d√πng 10% data
```

---

## 8. B√°o c√°o ƒë·ªì √°n

### C·∫•u tr√∫c b√°o c√°o (Word/LaTeX)

#### Ch∆∞∆°ng 1: Gi·ªõi thi·ªáu
- B·ªëi c·∫£nh: Drug discovery t·ªën k√©m
- B√†i to√°n: D·ª± ƒëo√°n DTI
- ƒê√≥ng g√≥p: GraphTransDTI

#### Ch∆∞∆°ng 2: C∆° s·ªü l√Ω thuy·∫øt
- Graph Neural Networks
- Transformer & Attention
- DTI prediction

#### Ch∆∞∆°ng 3: C√°c h∆∞·ªõng ·ª©ng d·ª•ng GNN trong y d∆∞·ª£c
- Molecular property prediction
- Drug-Drug Interaction
- **Drug-Target Interaction** ‚Üê ch·ªçn
- Drug-Disease association

#### Ch∆∞∆°ng 4: T·ªïng quan nghi√™n c·ª©u li√™n quan
- DeepDTA (2018)
- GraphDTA (2020)
- MolTrans (2022)
- Graphormer-DTI (2023)
- **Kho·∫£ng tr·ªëng**: Ch∆∞a c√≥ Cross-Attention

#### Ch∆∞∆°ng 5: Ph∆∞∆°ng ph√°p ƒë·ªÅ xu·∫•t
- Ki·∫øn tr√∫c GraphTransDTI
- Graph Transformer
- CNN + BiLSTM
- Cross-Attention
- Dataset: KIBA, DAVIS

#### Ch∆∞∆°ng 6: Th·ª±c nghi·ªám
- Setup: GPU, PyTorch
- Hyperparameters
- Training process
- **K·∫øt qu·∫£**:
  - B·∫£ng so s√°nh
  - Bi·ªÉu ƒë·ªì (training curve, scatter plot)
  - Ph√¢n t√≠ch

#### Ch∆∞∆°ng 7: K·∫øt lu·∫≠n & H∆∞·ªõng ph√°t tri·ªÉn
- T√≥m t·∫Øt ƒë√≥ng g√≥p
- H·∫°n ch·∫ø
- Future work: 3D structure, pre-training, interpretability

### T√†i li·ªáu tham kh·∫£o (‚â•15 papers)
- [1] Tang et al. (2014) KIBA
- [2] Davis et al. (2011) DAVIS
- [3] √ñzt√ºrk et al. (2018) DeepDTA
- [4] Nguyen et al. (2021) GraphDTA
- [5] Huang et al. (2022) MolTrans
- [6] Vaswani et al. (2017) Attention
- [7] Ying et al. (2021) Transformers for Graphs
- ... (c√≤n 8 papers n·ªØa)

### H√¨nh v·∫Ω c·∫ßn c√≥
1. **S∆° ƒë·ªì ki·∫øn tr√∫c t·ªïng th·ªÉ** (draw.io)
2. **Graph Transformer layer** (chi ti·∫øt)
3. **Protein encoder** (CNN + BiLSTM)
4. **Cross-Attention mechanism**
5. **Training curve** (loss, RMSE, Pearson)
6. **Scatter plot** (predicted vs true)
7. **Comparison bar chart** (baseline)

### File b√°o c√°o
- `docs/BaoCao_DoAn.docx` (ho·∫∑c .tex)
- `docs/Slide_BaoVe.pptx` (10-15 slide)

---

## 9. Checklist ho√†n th√†nh ƒë·ªì √°n

### Code ‚úÖ
- [x] Model architecture (4 files)
- [x] Dataloader (KIBA, DAVIS)
- [x] Training script
- [x] Evaluation script
- [x] Visualization
- [x] Notebook demo

### D·ªØ li·ªáu ‚úÖ
- [ ] Download KIBA
- [ ] Download DAVIS
- [ ] Test dataloader

### Experiments
- [ ] Train GraphTransDTI tr√™n KIBA (100 epochs)
- [ ] Evaluate tr√™n KIBA test
- [ ] Evaluate tr√™n DAVIS test
- [ ] So s√°nh v·ªõi baseline (t√¨m s·ªë li·ªáu t·ª´ papers)
- [ ] T·∫°o bi·ªÉu ƒë·ªì, b·∫£ng

### B√°o c√°o
- [ ] Vi·∫øt Ch∆∞∆°ng 1-7
- [ ] V·∫Ω s∆° ƒë·ªì ki·∫øn tr√∫c
- [ ] Th√™m h√¨nh ·∫£nh k·∫øt qu·∫£
- [ ] Tr√≠ch d·∫´n t√†i li·ªáu tham kh·∫£o
- [ ] L√†m slide thuy·∫øt tr√¨nh

### Ki·ªÉm tra cu·ªëi
- [ ] Code ch·∫°y ƒë∆∞·ª£c (test l·∫°i t·ª´ ƒë·∫ßu)
- [ ] README.md ƒë·∫ßy ƒë·ªß
- [ ] B√°o c√°o kh√¥ng l·ªói ch√≠nh t·∫£
- [ ] Slide d∆∞·ªõi 15 ph√∫t

---

## 10. Li√™n h·ªá & H·ªó tr·ª£

### T√†i li·ªáu
- **README.md**: H∆∞·ªõng d·∫´n t·ªïng quan
- **docs/MODEL_ARCHITECTURE.md**: Chi ti·∫øt ki·∫øn tr√∫c
- **data/DATA_DOWNLOAD_GUIDE.md**: H∆∞·ªõng d·∫´n t·∫£i data
- **notebooks/Train_GraphTransDTI.ipynb**: Demo notebook

### Code structure
```
GraphTransDTI/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ models/          ‚Üê Ki·∫øn tr√∫c m√¥ h√¨nh
‚îÇ   ‚îú‚îÄ‚îÄ dataloader/      ‚Üê X·ª≠ l√Ω d·ªØ li·ªáu
‚îÇ   ‚îú‚îÄ‚îÄ utils/           ‚Üê Metrics, visualization
‚îÇ   ‚îú‚îÄ‚îÄ train.py         ‚Üê Training script
‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py      ‚Üê Evaluation script
‚îú‚îÄ‚îÄ data/                ‚Üê Datasets
‚îú‚îÄ‚îÄ notebooks/           ‚Üê Jupyter notebooks
‚îú‚îÄ‚îÄ config.yaml          ‚Üê Hyperparameters
‚îî‚îÄ‚îÄ README.md
```

---

## üéØ K·∫øt lu·∫≠n

**GraphTransDTI** l√† m·ªôt ƒë·ªì √°n t·ªët nghi·ªáp ho√†n ch·ªânh v·ªÅ:
- ‚úÖ Deep Learning (Graph Transformer, Attention)
- ‚úÖ Bioinformatics (Drug-Target Interaction)
- ‚úÖ Software Engineering (clean code, documentation)

**Ch√∫c b·∫°n b·∫£o v·ªá th√†nh c√¥ng! üéìüöÄ**

---

**C·∫≠p nh·∫≠t**: 2025-01-14  
**Version**: 1.0
