# ==========================================
# GraphTransDTI Configuration
# DTI Prediction - KIBA/DAVIS/BindingDB
# ==========================================

# === Experiment Settings ===
experiment:
  name: "GraphTransDTI_KIBA"
  seed: 42
  device: "cuda"  # cuda / cpu
  log_dir: "./logs"
  checkpoint_dir: "./checkpoints"

# === Data Settings ===
data:
  dataset: "kiba"  # kiba / davis / bindingdb
  data_dir: "./data"
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1
  num_workers: 0  # Set to 0 for Windows compatibility
  pin_memory: false

# === Drug (SMILES) Settings ===
drug:
  max_atoms: 100  # Maximum number of atoms in molecule
  atom_features: 79  # RDKit atom feature dimension (44 atom type + 11 degree + 11 charge + 6 hybrid + 1 aromatic + 5 H + 1 chiral)
  use_edge_features: true
  edge_features: 12  # Bond type, conjugated, ring, etc.

# === Protein Settings ===
protein:
  max_length: 1000  # Maximum protein sequence length
  vocab_size: 26  # 20 amino acids + 5 special tokens (PAD, UNK, etc.)
  embedding_dim: 128

# === Model Architecture ===
model:
  # Drug Encoder - Graph Transformer
  drug_encoder:
    hidden_dim: 128
    num_layers: 4
    num_heads: 8
    dropout: 0.1
    feedforward_dim: 512
    use_edge_features: true
  
  # Protein Encoder - CNN + BiLSTM
  protein_encoder:
    cnn_filters: [32, 64, 96]  # 3 CNN layers
    cnn_kernel_sizes: [4, 8, 12]  # Motif windows
    lstm_hidden_dim: 128
    lstm_num_layers: 2
    lstm_dropout: 0.1
    bidirectional: true
  
  # Cross-Attention Fusion
  cross_attention:
    num_heads: 8
    dropout: 0.1
    hidden_dim: 128
  
  # Prediction Head
  predictor:
    hidden_dims: [256, 128, 64]  # FC layers
    dropout: 0.2
    output_dim: 1  # Binding affinity (regression)

# === Training Settings ===
training:
  batch_size: 64
  num_epochs: 100  # Full training with early stopping
  learning_rate: 0.0001
  weight_decay: 0.00001
  optimizer: "adam"  # adam / adamw
  scheduler: "reduce_on_plateau"  # reduce_on_plateau / cosine
  early_stopping_patience: 15
  gradient_clip: 1.0
  save_plots_every_epoch: true  # Auto-generate plots after each epoch

# === Loss Function ===
loss:
  type: "mse"  # mse / huber / smooth_l1
  log_transform: true  # Apply log to binding affinity labels

# === Evaluation Metrics ===
metrics:
  - "rmse"
  - "mse"
  - "pearson"
  - "spearman"
  - "ci"  # Concordance Index

# === Baseline Comparisons ===
baselines:
  - "DeepDTA"
  - "GraphDTA"
  - "MolTrans"
  - "Graphormer-DTI"

# === Augmentation (Optional) ===
augmentation:
  smiles_augment: false  # SMILES enumeration
  protein_mask: false    # Mask random amino acids
